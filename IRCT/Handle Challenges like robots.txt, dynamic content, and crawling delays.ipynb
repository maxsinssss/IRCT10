{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuo430D+xMCfVrEUdPplGU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H92LVy0KYZ0e","executionInfo":{"status":"ok","timestamp":1745340732218,"user_tz":-330,"elapsed":36533,"user":{"displayName":"Max Sins","userId":"02396150637805525832"}},"outputId":"32acea0f-83c4-4eb2-95e6-627d45c7696c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n","Collecting robotexclusionrulesparser\n","  Downloading robotexclusionrulesparser-1.7.1.tar.gz (31 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n","Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: robotexclusionrulesparser\n","  Building wheel for robotexclusionrulesparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for robotexclusionrulesparser: filename=robotexclusionrulesparser-1.7.1-py3-none-any.whl size=12057 sha256=ddc7054362d9b01026d63b8f2a2e16e9791c59fb562d878fe5ac7fec6d676493\n","  Stored in directory: /root/.cache/pip/wheels/51/db/cd/5be41448be8f9f645f7467876ed03d2d85434bb3061fa4ca2d\n","Successfully built robotexclusionrulesparser\n","Installing collected packages: robotexclusionrulesparser, wsproto, outcome, trio, trio-websocket, selenium\n","Successfully installed outcome-1.3.0.post0 robotexclusionrulesparser-1.7.1 selenium-4.31.0 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n","Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,259 kB]\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,148 kB]\n","Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,696 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,842 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,834 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,098 kB]\n","Fetched 27.4 MB in 3s (8,475 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","34 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools\n","  systemd-hwe-hwdb udev\n","Suggested packages:\n","  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n","The following NEW packages will be installed:\n","  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n","  squashfs-tools systemd-hwe-hwdb udev\n","The following packages will be upgraded:\n","  libudev1\n","1 upgraded, 8 newly installed, 0 to remove and 33 not upgraded.\n","Need to get 30.3 MB of archives.\n","After this operation, 123 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n","Fetched 30.3 MB in 0s (64.6 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package apparmor.\n","(Reading database ... 126333 files and directories currently installed.)\n","Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n","Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n","Selecting previously unselected package squashfs-tools.\n","Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n","Unpacking squashfs-tools (1:4.5-3build1) ...\n","Preparing to unpack .../libudev1_249.11-0ubuntu3.15_amd64.deb ...\n","Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n","Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n","Selecting previously unselected package udev.\n","(Reading database ... 126533 files and directories currently installed.)\n","Preparing to unpack .../udev_249.11-0ubuntu3.15_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.15) ...\n","Selecting previously unselected package libfuse3-3:amd64.\n","Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n","Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n","Selecting previously unselected package snapd.\n","Preparing to unpack .../snapd_2.67.1+22.04_amd64.deb ...\n","Unpacking snapd (2.67.1+22.04) ...\n","Setting up apparmor (3.0.4-2ubuntu2.4) ...\n","Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n","Setting up squashfs-tools (1:4.5-3build1) ...\n","Setting up udev (249.11-0ubuntu3.15) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n","Setting up snapd (2.67.1+22.04) ...\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n","Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n","Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n","Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n","Selecting previously unselected package chromium-browser.\n","(Reading database ... 126762 files and directories currently installed.)\n","Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","=> Installing the chromium snap\n","==> Checking connectivity with the snap store\n","===> System doesn't have a working snapd, skipping\n","Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.5) ...\n","Setting up systemd-hwe-hwdb (249.11.5) ...\n","Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Processing triggers for udev (249.11-0ubuntu3.15) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n","Allowed to crawl: True\n","Crawled: https://www.youtube.com/ -> YouTube\n","Crawled: https://www.youtube.com/about/ -> About YouTube - YouTube\n","Crawled: https://www.youtube.com/about/press/ -> \n","          \n","            \n","              Official YouTube Blog for Latest YouTube News & Insights\n","            \n","          \n","          \n","        \n","\n","Indexed Pages:\n","https://www.youtube.com/ : YouTube\n","https://www.youtube.com/about/ : About YouTube - YouTube\n","https://www.youtube.com/about/press/ : \n","          \n","            \n","              Official YouTube Blog for Latest YouTube News & Insights\n","            \n","          \n","          \n","        \n"]}],"source":["\n","import sys\n","sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')\n","\n","import time\n","import requests\n","from bs4 import BeautifulSoup\n","from urllib.parse import urljoin\n","import robotexclusionrulesparser\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","\n","\n","def is_allowed(url, user_agent='*'):\n","    parsed_url = requests.utils.urlparse(url)\n","    base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt\"\n","\n","    rp = robotexclusionrulesparser.RobotExclusionRulesParser()\n","    try:\n","        robots_txt = requests.get(base_url, timeout=5).text\n","        rp.parse(robots_txt)\n","        return rp.is_allowed(user_agent, url)\n","    except Exception as e:\n","        print(f\"Could not fetch robots.txt for {url}: {e}\")\n","        return True\n","\n","\n","def fetch_dynamic_content(url):\n","    options = Options()\n","    options.add_argument('--headless')\n","    options.add_argument('--disable-gpu')\n","    options.add_argument('--no-sandbox')\n","    driver = webdriver.Chrome('chromedriver', options=options)\n","\n","    try:\n","        driver.get(url)\n","        html = driver.page_source\n","    finally:\n","        driver.quit()\n","    return html\n","\n","\n","def crawler_with_delay(start_url, delay=2, max_pages=5, use_selenium=False):\n","    visited = set()\n","    to_visit = [start_url]\n","    index = {}\n","\n","    while to_visit and len(visited) < max_pages:\n","        url = to_visit.pop(0)\n","        if url not in visited:\n","            if is_allowed(url):\n","                try:\n","                    if use_selenium:\n","                        html = fetch_dynamic_content(url)\n","                        soup = BeautifulSoup(html, 'html.parser')\n","                    else:\n","                        response = requests.get(url, timeout=10)\n","                        if response.status_code == 200:\n","                            soup = BeautifulSoup(response.text, 'html.parser')\n","                        else:\n","                            print(f\"Failed to fetch {url} with status code {response.status_code}\")\n","                            continue\n","\n","                    title = soup.title.string if soup.title else 'No Title'\n","                    index[url] = title\n","                    print(f\"Crawled: {url} -> {title}\")\n","\n","                    for link in soup.find_all('a', href=True):\n","                        absolute_link = urljoin(url, link['href'])\n","                        if absolute_link not in visited and absolute_link not in to_visit:\n","                            to_visit.append(absolute_link)\n","\n","                except Exception as e:\n","                    print(f\"Failed to crawl {url}: {e}\")\n","\n","                visited.add(url)\n","                time.sleep(delay)\n","            else:\n","                print(f\"Crawling disallowed for: {url}\")\n","    return index\n","\n","\n","if __name__ == \"__main__\":\n","    start_url = \"https://www.youtube.com/\"\n","    print(\"Allowed to crawl:\", is_allowed(start_url))\n","    indexed_pages = crawler_with_delay(start_url, delay=2, max_pages=3, use_selenium=False)\n","\n","    print(\"\\nIndexed Pages:\")\n","    for url, title in indexed_pages.items():\n","        print(url, \":\", title)\n"]}]}